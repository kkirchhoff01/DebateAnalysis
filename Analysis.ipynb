{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create sentiment dictionary from AFINN-111 list (free online)\n",
    "sentiment_dict = {}\n",
    "for line in open('AFINN/AFINN-111.txt'):\n",
    "    word, score = line.split('\\t')\n",
    "    sentiment_dict[word] = int(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = ['01-15', '02-06', '03-15', '12-15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize file list and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = ['transcript01-15.txt', 'transcript02-06.txt', 'transcript03-15.txt', 'transcript12-15.txt']\n",
    "statements = {}\n",
    "transcripts = ['transcripts/' + f for f in files]\n",
    "names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moderators = {'02-06':['MUIR'], '01-15':['CAVUTO', 'BARTIROMO'], '12-15':['BLITZER'], '03-15':['TAPPER']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names are extracted using regex.\n",
    "\n",
    "Transcript speaker format is assumed to be\n",
    "> SPEAKER: statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = re.compile(r'([A-Z]+)\\:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in transcripts:\n",
    "    with open(t, 'r') as fh:\n",
    "        for n in re.findall(name, fh.read()):\n",
    "            if n not in names.keys():\n",
    "                names[n] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse transcripts\n",
    "\n",
    "Statements are stored in a list of tuples containing the statement number and statement string.\n",
    "\n",
    "They are then split and stored by speaker and file names in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debate_pos = {}\n",
    "j = 0\n",
    "for t in files:\n",
    "    t_name = t[-9:-4]\n",
    "    statements[t_name] = []\n",
    "    with open('transcripts/' + t, 'r') as fh:\n",
    "        or_names = '|'.join(names.keys())\n",
    "        pattern = re.compile(r\"({0})(.+\\n)|(\\n)(.+)(\\n)\".format(or_names))\n",
    "\n",
    "        for statement in re.findall(pattern, fh.read()):\n",
    "            statements[t_name].append((j,''.join([s for s in statement if s not in ['', '\\n', '(APPLAUSE)']])))\n",
    "            j+=1\n",
    "        debate_pos[t_name] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_speaker = ''\n",
    "for key in dates:\n",
    "    for n in names.keys():\n",
    "        names[n][key] = []\n",
    "    for state in statements[key]:\n",
    "        if len(state[1]) < 1:\n",
    "            continue\n",
    "        statement = state[1]\n",
    "        if statement.split(':')[0] in names.keys():\n",
    "            current_speaker = statement.split(':')[0]\n",
    "            names[current_speaker][key].append((state[0],statement.split(':')[1]))\n",
    "        elif current_speaker in names.keys():\n",
    "            names[current_speaker][key].append((state[0],statement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statement parsing\n",
    "\n",
    "Create a statement dictionary containing the speaker names.\n",
    "The speaker names hold a second set of dictionaries with a 2D list of statements and the words in those statements.\n",
    "\n",
    "All words are lowercase, and stopwords are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statement_dict = {}\n",
    "for n in names.keys():\n",
    "    statement_dict[n] = {}\n",
    "    for t in files:\n",
    "        t_name = t[-9:-4]\n",
    "        statement_dict[n][t_name] = []\n",
    "        for line in names[n][t_name]:\n",
    "            st = re.sub(r'(\\xe2\\x80\\x99)',r\"'\",line[1].lower().strip('\\n'))\n",
    "            #st = line[1].lower().strip('\\n').decode('utf-8')\n",
    "\n",
    "            if st != '' and len(st) > 0:\n",
    "                statement_dict[n][t_name].append((line[0],st))\n",
    "        if len(statement_dict[n][t_name]) == 0:\n",
    "            del statement_dict[n][t_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sentiment scores\n",
    "\n",
    "Sentiment is scored from AFINN-111.\n",
    "They are formated in lists of length 2 (`[pos, neg]`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data frame with statement\n",
    "### Columns:\n",
    "- Statement_Num: Position number of statement in transcripts\n",
    "- Statement: Statement string\n",
    "- Word_Count: Number of words in statement\n",
    "- Setiment: Sentiment score calculated above\n",
    " * Sentiment is scored from AFINN-111.\n",
    " * They are formated in lists of length 2 (`[pos, neg]`)\n",
    "- Sentence_Count: Number of sentences in statement\n",
    "- Question (obtained from add_questions function): Most recent question asked by a moderator\n",
    " * Format: \n",
    "  > [Statement Number] [Moderator] [Question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_speaker_df(speaker, date_list=dates):\n",
    "    statement_list = []\n",
    "    for d in date_list:\n",
    "        statement_list += [s for s in statement_dict[speaker][d]]\n",
    "    scores = {}\n",
    "    scores[speaker] = []\n",
    "    sentence_count = []\n",
    "    word_count = []\n",
    "    t_scores = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['Statement_Num'] = [s[0] for s in statement_list]\n",
    "    df['Statement'] = [s[1].decode('utf-8') for s in statement_list]\n",
    "\n",
    "    for statement in df['Statement'].values:\n",
    "        sentences = nltk.tokenize.sent_tokenize(statement)\n",
    "        sentence_count.append(len(sentences))\n",
    "        wc = 0\n",
    "        s_scores = []\n",
    "        for sentence in sentences:\n",
    "            words = nltk.tokenize.word_tokenize(sentence) \n",
    "            pos,neg=0,0\n",
    "            for word in words:\n",
    "                score = sentiment_dict.get(word,0)\n",
    "                if score > 0:\n",
    "                    pos += score\n",
    "                if score < 0:\n",
    "                    neg += score\n",
    "            s_scores.append([pos,neg])\n",
    "            wc += len(words)\n",
    "        word_count.append(wc)\n",
    "        t_scores.append(sum(sum(s) for s in s_scores))\n",
    "    \n",
    "    df['Word_count'] = word_count\n",
    "    df['Sentiment'] = t_scores\n",
    "    df['Sentence_Count'] = sentence_count\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_questions(df):\n",
    "    question_list = []\n",
    "    for d in dates:\n",
    "        for mod in moderators[d]:\n",
    "            question_list += [(n, mod, s.decode('utf-8')) for n,s in statement_dict[mod][d]]\n",
    "    questions = []\n",
    "    for value in df['Statement_Num']:\n",
    "        for q in range(len(question_list)):\n",
    "            if question_list[q][0] < value and question_list[q+1][0] > value:\n",
    "                questions.append(str(question_list[q][0]) + ' ' +question_list[q][1] +' '+ question_list[q][2])\n",
    "                break\n",
    "                \n",
    "    df['Question'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump = get_speaker_df('TRUMP')#.sort('Statement_Num')\n",
    "add_questions(trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement_Num</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentence_Count</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  96</td>\n",
       "      <td>  it's not fear and terror, it's reality. you j...</td>\n",
       "      <td>  24</td>\n",
       "      <td> -5</td>\n",
       "      <td> 2</td>\n",
       "      <td> 95 CAVUTO the president says that that doctor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>  98</td>\n",
       "      <td> you look at california, you look, frankly, at ...</td>\n",
       "      <td> 102</td>\n",
       "      <td>  0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 95 CAVUTO the president says that that doctor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>  99</td>\n",
       "      <td> that could be the great trojan horse. it could...</td>\n",
       "      <td>  81</td>\n",
       "      <td> 12</td>\n",
       "      <td> 6</td>\n",
       "      <td> 95 CAVUTO the president says that that doctor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 100</td>\n",
       "      <td> you look at the kind of damage that two people...</td>\n",
       "      <td>  94</td>\n",
       "      <td> -1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 95 CAVUTO the president says that that doctor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 132</td>\n",
       "      <td>                              but i was born here.</td>\n",
       "      <td>   6</td>\n",
       "      <td>  0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 111 CAVUTO do you want to try to close this to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Statement_Num                                          Statement  \\\n",
       "0             96   it's not fear and terror, it's reality. you j...   \n",
       "1             98  you look at california, you look, frankly, at ...   \n",
       "2             99  that could be the great trojan horse. it could...   \n",
       "3            100  you look at the kind of damage that two people...   \n",
       "4            132                               but i was born here.   \n",
       "\n",
       "   Word_count  Sentiment  Sentence_Count  \\\n",
       "0          24         -5               2   \n",
       "1         102          0               4   \n",
       "2          81         12               6   \n",
       "3          94         -1               3   \n",
       "4           6          0               1   \n",
       "\n",
       "                                            Question  \n",
       "0  95 CAVUTO the president says that that doctor ...  \n",
       "1  95 CAVUTO the president says that that doctor ...  \n",
       "2  95 CAVUTO the president says that that doctor ...  \n",
       "3  95 CAVUTO the president says that that doctor ...  \n",
       "4  111 CAVUTO do you want to try to close this to...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "\n",
    "1. Use NLTK to contextualize statements.\n",
    " * Find key words and topics\n",
    "2. Use scikit-learn to analyze speaker attitudes towards key words and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
